{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")\n",
    "inputs = tokenizer.encode(\"Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> It is yellow.</s>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Context: This banana is very sweet. Question: What color is the banana? Answer:\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> yellow</s>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"\"\"Given the context \"This banana is very sweet.\" and the question \"What color is the banana?\", write an answer\"\"\", return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Amy likes bananas because they are very sweet. Chris doesn't like bananas.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Given the context \"Bananas are very sweet, but they can be the cause of tropical diseases.\" and the conversation \"Amy: I like bananas. Chris: Why? Amy: Because they are very sweet! Chris: I don't like bananas. Amy: Why? Chris:\", write a follow up conversation\"\"\"\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt is important. Example:\n",
    "\n",
    "Given the context \"Bananas are very sweet, but they can be the cause of tropical diseases.\" and the conversation \"Amy: I like bananas. Chris: Why? Amy: Because they are very sweet! Chris: I don't like bananas. Amy: Why? Chris:\", **write Chris' answer**\n",
    "\n",
    "**Answer : <pad> Amy doesn't like bananas because they can be the cause of tropical diseases.</s>**\n",
    "\n",
    "\n",
    "Given the context \"Bananas are very sweet, but they can be the cause of tropical diseases.\" and the conversation \"Amy: I like bananas. Chris: Why? Amy: Because they are very sweet! Chris: I don't like bananas. Amy: Why? Chris:\", **write a follow up conversation**\n",
    "\n",
    "**Answer : <pad> Amy likes bananas because they are very sweet. Chris doesn't like bananas.**\n",
    "\n",
    "\n",
    "Given the context \"Bananas are very sweet, but they can be the cause of tropical diseases.\" and the conversation \"Amy: I like bananas. Chris: Why? Amy: Because they are very sweet! Chris: I don't like bananas. Amy: Why?\", **what did Chris say?**\n",
    "\n",
    "**Answer : <pad> Chris doesn't like bananas because they can be the cause of tropical diseases.</s>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open(\"train-v2.0.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answerable_single_example(index):\n",
    "    \"\"\"index is the index of the unanswerable question you want to extract, in the order given by the dataset\n",
    "       1 gives the first unanswerable question found, 100 the 100th one.\"\"\"\n",
    "    count = 0\n",
    "    for data in tqdm(dataset[\"data\"]):\n",
    "        for paragraph in data[\"paragraphs\"]:\n",
    "            for question in paragraph[\"qas\"]: #question is a dict\n",
    "                if not question[\"is_impossible\"]:\n",
    "                    count += 1\n",
    "                    if count == index:\n",
    "                        return question, paragraph[\"context\"]\n",
    "\n",
    "def get_unanswerable_single_example(index):\n",
    "    \"\"\"index is the index of the unanswerable question you want to extract, in the order given by the dataset\n",
    "       1 gives the first unanswerable question found, 100 the 100th one.\"\"\"\n",
    "    count = 0\n",
    "    for data in tqdm(dataset[\"data\"]):\n",
    "        for paragraph in data[\"paragraphs\"]:\n",
    "            for question in paragraph[\"qas\"]: #question is a dict\n",
    "                if question[\"is_impossible\"]:\n",
    "                    count += 1\n",
    "                    if count == index:\n",
    "                        return question, paragraph[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/442 [00:00<00:00, 5211.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]. Question: What category of game is Legend of Zelda: Australia Twilight?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> action-adventure</s>'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer(context, question):\n",
    "    q = question[\"question\"]\n",
    "    text = \"Context: \"+context+\". Question: \"+q\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs)\n",
    "    print(text)\n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "q, c = get_unanswerable_single_example(1)\n",
    "infer(c, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/442 [00:00<00:00, 5300.86it/s]\n",
      "  1%|          | 4/442 [00:00<00:00, 4908.49it/s]\n",
      " 17%|█▋        | 73/442 [00:00<00:00, 12353.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]. Question: What category of game is Legend of Zelda: Australia Twilight?\n",
      "Context: The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]\n",
      "Question: What category of game is Legend of Zelda: Australia Twilight? Answer: <pad> action-adventure</s>\n",
      "Question: What consoles can be used to play Twilight Princess? Answer: GameCube and Wii\n",
      "\n",
      " Context: Slavs are the largest Indo-European ethno-linguistic group in Europe. They inhabit Central Europe, Eastern Europe, Southeast Europe, North Asia and Central Asia. Slavs speak Indo-European Slavic languages and share, to varying degrees, some cultural traits and historical backgrounds. From the early 6th century they spread to inhabit most of Central and Eastern Europe and Southeast Europe, whilst Slavic mercenaries fighting for the Byzantines and Arabs settled Asia Minor and even as far as Syria. The East Slavs colonised Siberia and Central Asia.[better source needed] Presently over half of Europe's territory is inhabited by Slavic-speaking communities, but every Slavic ethnicity has emigrated to other continents. Question: What percentage of Central Asia is inhabited by Slavic-speaking communities?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> 5%</s>'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_answerable_single_example(index):\n",
    "    \"\"\"index is the index of the unanswerable question you want to extract, in the order given by the dataset\n",
    "       1 gives the first unanswerable question found, 100 the 100th one.\"\"\"\n",
    "    count = 0\n",
    "    for data in tqdm(dataset[\"data\"]):\n",
    "        for paragraph in data[\"paragraphs\"]:\n",
    "            for question in paragraph[\"qas\"]: #question is a dict\n",
    "                if not question[\"is_impossible\"]:\n",
    "                    count += 1\n",
    "                    if count == index:\n",
    "                        return question, paragraph[\"context\"]\n",
    "\n",
    "def get_unanswerable_single_example(index):\n",
    "    \"\"\"index is the index of the unanswerable question you want to extract, in the order given by the dataset\n",
    "       1 gives the first unanswerable question found, 100 the 100th one.\"\"\"\n",
    "    count = 0\n",
    "    for data in tqdm(dataset[\"data\"]):\n",
    "        for paragraph in data[\"paragraphs\"]:\n",
    "            for question in paragraph[\"qas\"]: #question is a dict\n",
    "                if question[\"is_impossible\"]:\n",
    "                    count += 1\n",
    "                    if count == index:\n",
    "                        return question, paragraph[\"context\"]\n",
    "\n",
    "q, c = get_unanswerable_single_example(1)\n",
    "q1, c1 = get_answerable_single_example(2070)\n",
    "q2, c2 = get_unanswerable_single_example(6000)\n",
    "text = \"Context: \"+c+\"\\nQuestion: \"+q[\"question\"]+\" Answer: \"+infer(c, q)+\"\\nQuestion: \"+q1[\"question\"]+\" Answer: \"+q1[\"answers\"][0][\"text\"]+\"\\n\\n Context: \"+c2+\" Question: \"+q2[\"question\"]\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs)\n",
    "print(text)\n",
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "321b428eb2f22c8dd426e302012007662aaddde80543b37e06bd4b8428c821cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('KGD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
